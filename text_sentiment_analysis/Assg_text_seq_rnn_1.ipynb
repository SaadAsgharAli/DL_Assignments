{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Assg_text_seq_rnn_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITqsW5UkRDmK",
        "colab_type": "text"
      },
      "source": [
        "## Assignment: Amazon Reviews for sentiment analysis - related to chp#6 - by Sir Anees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7WPwsoUR2v3",
        "colab_type": "text"
      },
      "source": [
        "### Author: SAAD - AIC035848"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLSSb4rRtmV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import bz2\n",
        "import os\n",
        "import random\n",
        "#import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sVx8dz2t3ZW",
        "colab_type": "code",
        "outputId": "2d5b2b97-8da2-464e-837e-a94d12ca8c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEcTrpSTvTbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for moving data to my drive\n",
        "!mv test.ft.txt.bz2 \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "base_dir = 'drive/My Drive/Colab Notebooks/test.ft.txt.bz2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW7VL3hbtmWZ",
        "colab_type": "code",
        "outputId": "9f2ce8e9-56bb-455c-a47f-a827d79f1f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Load the training data \n",
        "data = bz2.BZ2File(base_dir)\n",
        "data = data.readlines()\n",
        "data = [x.decode('utf-8') for x in data]\n",
        "print(len(data)) #= 4 lac \n",
        "\n",
        "# On jupyter: PC got hanged several times. This cell took a lot of time when run first time. i think about 20m\n",
        "# On colab: less than a min"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDkPgo7stmW2",
        "colab_type": "code",
        "outputId": "76916714-ffe7-4c8d-f8d9-672450abc38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "data[1:5]\n",
        "data[5:10]\n",
        "data[10:13]\n",
        "# Contains label1 and label2 in the beginning of each text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__label__2 Great book for travelling Europe: I currently live in Europe, and this is the book I recommend for my visitors. It covers many countries, colour pictures, and is a nice starter for before you go, and once you are there.\\n',\n",
              " '__label__1 Not!: If you want to listen to El Duke , then it is better if you have access to his shower,this is not him, it is a gimmick,very well orchestrated.\\n',\n",
              " '__label__1 A complete Bust: This game requires quicktime 5.0 to work...if you have a better version of quicktime (I have 7.5), it will ask you to install the quicktime available on the CD...if you click no, it will not let you play. So, I begrudgingly clicked yes on the third try, and it installed quicktime 5, THEN it tells me to please install the quicktime available on the disc. It KEPT telling me that, even after I uninstalled my version of quicktime 7.5, and reinstalled Barbie Rapunzel and quicktime 5. Very frustrating, and the game absolutely will not work for me. It keeps telling me over and over, to install quicktime 5, tho I\\'ve been through the installation process repeatedly. It is NOT my \"operating system limitations\". This is a brand new computer...merely weeks old with all the state of the art contraptions.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKanfDJ-tmXP",
        "colab_type": "code",
        "outputId": "798cc44e-6875-47bd-aa08-c6602efe35ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(data)   # its elements are string\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTpEK-QStmYq",
        "colab_type": "code",
        "outputId": "74faecc3-19c8-4ebf-ef92-daa7e46c6110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# rough:\n",
        "# random.sample to select multiple items from a list without repeating\n",
        "\n",
        "aList = [20, 40, 80, 100, 120]\n",
        "print (\"choosing 3 random items from a list using random.sample() function\")\n",
        "sampled_list = random.sample(aList, 3)\n",
        "print(sampled_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "choosing 3 random items from a list using random.sample() function\n",
            "[120, 20, 100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1YR732Nw5aM",
        "colab_type": "code",
        "outputId": "a2385bbe-4366-46b1-fbd2-43d403e8d19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# data extraction:\n",
        "small_data = random.sample(data, 5)\n",
        "small_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__label__2 Exactly what you need to renew the fan blades: These Fan Blade arms were exactly what I needed and they look beautiful on the plades. The price was perfect.\\n',\n",
              " \"__label__1 Disappointing: I'm only giving it two stars because Mr. Harris did keep me glued until the bitter end. Otherwise, I'd give it one star. The ending is just completely implausible and idiotic. I considered it an insult to what little intelligence the author gives me credit for.If you're like the 2 or 3 other million people in the country and decide to read it against my advice, grab a dictionary. Mr. Harris likes to place 5 syllable words where a single syllable would do just fine. And don't use a Webster's dictionary either -- he uses words not found in that particular dictionary.\\n\",\n",
              " \"__label__1 Disappointed! :(: This camera was handed down to me, because it didn't work on my brother's computer, which uses windowsXP. Beware... It will not work with windowsXP. Well, I was very excited, because I already owned a PolaroidPDC640, which always gave me great pictures. I was very disappointed when I saw the quality of pictures this camera took. They are all blurry. It's almost looks like their is something smeared on the lens. I cleaned the lens, but still no improvement. If you want clear, crisp pictures... I do not recommend this camera, not even for online viewing. This one is going to my 6yr old.\\n\",\n",
              " \"__label__1 It doesn't work: My previous review was too hopeful. The lights do not work and never have. The manufacturer said to replace the battery (which we certainly never had the chance to drain in the first place) and we found that the battery costs upwards of $40. To replace a battery that we did not utilize at 1/3 the cost of the umbrella itself, out of our own pocket, is unseemly and we'll only pay around $20 to return it for a refund. Sad, really. I was excited at the prospect of the lights. The umbrella itself is nice, sturdy and appealing, but not for the cost it will end up for a feature that's not even guaranteed to work. Also, there is no warranty whatsoever so don't keep it for long. If it doesn't work right away, return it just as quickly in order to get any kind of refund. I do NOT recommend this product to anyone.\\n\",\n",
              " \"__label__2 Essential book for photographers: I haven't finished this book yet, as it's a little dry for my reading style preference, but it definitely contains the basics any photographer needs to know.\\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spm-WuZ5z9vZ",
        "colab_type": "code",
        "outputId": "a8b1e3d3-60a8-459f-beb5-ce792474ab53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "print('length of characters of longest string=',len(max(small_data, key=len)))\n",
        "a = max(small_data, key=len)\n",
        "print(a)\n",
        "a = a.count(' ')\n",
        "print('its no. of spaces=', a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of characters of longest string= 843\n",
            "__label__1 It doesn't work: My previous review was too hopeful. The lights do not work and never have. The manufacturer said to replace the battery (which we certainly never had the chance to drain in the first place) and we found that the battery costs upwards of $40. To replace a battery that we did not utilize at 1/3 the cost of the umbrella itself, out of our own pocket, is unseemly and we'll only pay around $20 to return it for a refund. Sad, really. I was excited at the prospect of the lights. The umbrella itself is nice, sturdy and appealing, but not for the cost it will end up for a feature that's not even guaranteed to work. Also, there is no warranty whatsoever so don't keep it for long. If it doesn't work right away, return it just as quickly in order to get any kind of refund. I do NOT recommend this product to anyone.\n",
            "\n",
            "its no. of spaces= 159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J8CkCAytmY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Listing 6.1 - Word-level one-hot encoding (toy example)\n",
        "\n",
        "token_index = {}\n",
        "for sample in small_data:\n",
        "  for word in sample.split():\n",
        "      if word not in token_index:\n",
        "        token_index[word] = len(token_index) + 1\n",
        "max_length = a + 100\n",
        "results = np.zeros(shape=(len(small_data), max_length, max(token_index.values())+1 ))\n",
        "for i, sample in enumerate(small_data):\n",
        "  for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "    index = token_index.get(word)\n",
        "    results[i, j, index] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10QcKD893h6p",
        "colab_type": "code",
        "outputId": "5a56c0d6-dfcd-464c-d45a-1d8e9ffe01a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "print(results.shape)\n",
        "# for i in range(5):\n",
        "#   print(results[i],'\\n')\n",
        "each_array_length = []\n",
        "\n",
        "s=np.where([results[0]==1])\n",
        "#print(s)  # length = 3\n",
        "print('text1: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "s=np.where([results[1]==1])\n",
        "print('text2: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "s=np.where([results[2]==1])\n",
        "print('text3: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "s=np.where([results[3]==1])\n",
        "print('text4: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "s=np.where([results[4]==1])\n",
        "print('text5: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "\n",
        "print('\\n\\nlength of all arrays =', each_array_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 259, 266)\n",
            "text1: locations where one hot encoding is 1 = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "text2: locations where one hot encoding is 1 = [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103]\n",
            "text3: locations where one hot encoding is 1 = [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106]\n",
            "text4: locations where one hot encoding is 1 = [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]\n",
            "text5: locations where one hot encoding is 1 = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31]\n",
            "\n",
            "\n",
            "length of all arrays = [30, 104, 107, 160, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRtIjw2m4RGQ",
        "colab_type": "code",
        "outputId": "43e9a2a8-1e4b-487b-a6d4-1daa7b13fa83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Listing 6.3 - Using Keras for word-level one-hot encoding\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(small_data)\n",
        "sequences = tokenizer.texts_to_sequences(small_data)\n",
        "one_hot_results = tokenizer.texts_to_matrix(small_data, mode='binary')  # result\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' %len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 235 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFev3It34RP_",
        "colab_type": "code",
        "outputId": "c274975f-a0d7-4903-d2bc-5299c551c463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "one_hot_results.shape == (5,1000)\n",
        "one_hot_results[0]\n",
        "each_array_length = []\n",
        "\n",
        "s=np.where([one_hot_results[0]==1])\n",
        "print('text1: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "s=np.where([one_hot_results[1]==1])\n",
        "print('text2: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "s=np.where([one_hot_results[2]==1])\n",
        "print('text3: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "s=np.where([one_hot_results[3]==1])\n",
        "print('text4: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "s=np.where([one_hot_results[4]==1])\n",
        "print('text5: locations where one hot encoding is 1 =', s[1])\n",
        "each_array_length.append(len(s[1]))\n",
        "\n",
        "print('\\n\\nlength of all arrays =', each_array_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text1: locations where one hot encoding is 1 = [ 1  2  4  6  9 14 20 21 22 34 35 36 37 77 78 79 80 81 82 83 84 85 86 87\n",
            " 88 89]\n",
            "text2: locations where one hot encoding is 1 = [  1   2   3   4   5   6   7   8  10  14  15  16  17  18  19  20  21  23\n",
            "  24  25  26  27  38  39  40  41  42  43  44  45  46  47  48  49  50  51\n",
            "  52  53  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105\n",
            " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
            " 124 125 126 127 128 129 130 131 132 133 134]\n",
            "text3: locations where one hot encoding is 1 = [  1   2   3   4   5   7   8   9  10  11  12  13  14  15  16  17  19  22\n",
            "  23  25  28  29  30  31  35  37  44  46  52  54  55  56  57  58  59  60\n",
            "  61  62  63 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
            " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
            " 168 169 170 171]\n",
            "text4: locations where one hot encoding is 1 = [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18  19\n",
            "  24  25  27  29  31  32  33  38  41  42  43  47  48  51  53  56  58  61\n",
            "  62  63  64  65  66  67  68  69  70  71  72  73  74  75 172 173 174 175\n",
            " 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n",
            " 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211\n",
            " 212 213 214 215 216 217 218 219 220]\n",
            "text5: locations where one hot encoding is 1 = [  1   2   3   4   7   8  11  14  15  20  31  45  59  74  75  76 221 222\n",
            " 223 224 225 226 227 228 229 230 231 232 233 234 235]\n",
            "\n",
            "\n",
            "length of all arrays = [26, 83, 76, 99, 31]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0y65dreBtFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Listing 6.4 - Word-level one-hot encoding with hashing trick (toy example)\n",
        "\n",
        "dimensionality = 1000\n",
        "max_length = a-72\n",
        "results = np.zeros((len(small_data), max_length, dimensionality))\n",
        "for i, sample in enumerate(small_data):\n",
        "  for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "    index = abs(hash(word)) % dimensionality\n",
        "    results[i, j, index] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIHYTNjvBtKF",
        "colab_type": "code",
        "outputId": "31df7923-51c7-4d97-b119-903c5f928b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "print(results.shape,'\\n')\n",
        "# Why not s[0]: It is useless below. That's why brother s[1] is used everywhere uptill now\n",
        "loa2 = []\n",
        "\n",
        "print('sample 1:'); loa=[]\n",
        "for i in range(results.shape[1]):\n",
        "  s=np.where([results[0,i]==1])\n",
        "  if len(s[1]) != 0:\n",
        "    loa.append(s[1][0])\n",
        "print(loa)\n",
        "loa2.append(len(loa))\n",
        "\n",
        "\n",
        "print('sample 2:'); loa=[]\n",
        "for i in range(results.shape[1]):\n",
        "  s=np.where([results[1,i]==1])\n",
        "  if len(s[1]) != 0:\n",
        "    loa.append(s[1][0])\n",
        "print(loa)\n",
        "loa2.append(len(loa))\n",
        "\n",
        "print('sample 3:'); loa=[]\n",
        "for i in range(results.shape[1]):\n",
        "  s=np.where([results[2,i]==1])\n",
        "  if len(s[1]) != 0:\n",
        "    loa.append(s[1][0])\n",
        "print(loa)\n",
        "loa2.append(len(loa))\n",
        "\n",
        "print('sample 4:'); loa=[]\n",
        "for i in range(results.shape[1]):\n",
        "  s=np.where([results[3,i]==1])\n",
        "  if len(s[1]) != 0:\n",
        "    loa.append(s[1][0])\n",
        "print(loa)\n",
        "loa2.append(len(loa))\n",
        "\n",
        "print('sample 5:'); loa=[]\n",
        "for i in range(results.shape[1]):\n",
        "  s=np.where([results[4,i]==1])\n",
        "  if len(s[1]) != 0:\n",
        "    loa.append(s[1][0])\n",
        "print(loa)\n",
        "loa2.append(len(loa))\n",
        "\n",
        "print('\\n\\nlength of all arrays =', loa2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 87, 1000) \n",
            "\n",
            "sample 1:\n",
            "[753, 277, 139, 101, 674, 132, 119, 321, 109, 515, 284, 870, 790, 879, 792, 900, 139, 919, 941, 571, 24, 555, 134, 494, 321, 428, 288, 41, 38, 537]\n",
            "sample 2:\n",
            "[114, 959, 185, 133, 99, 868, 366, 484, 259, 649, 814, 504, 158, 961, 715, 220, 321, 121, 199, 939, 936, 490, 868, 179, 241, 288, 86, 310, 656, 35, 546, 571, 456, 919, 443, 868, 286, 442, 132, 139, 607, 584, 321, 870, 358, 961, 425, 97, 114, 79, 321, 154, 974, 931, 959, 125, 751, 105, 321, 7, 571, 302, 132, 615, 868, 721, 888, 285, 493, 692, 479, 649, 814, 346, 132, 85, 697, 445, 21, 363, 692, 493, 445, 408, 717, 656, 769]\n",
            "sample 3:\n",
            "[114, 490, 368, 831, 663, 38, 699, 117, 132, 938, 259, 868, 300, 382, 494, 888, 986, 725, 301, 820, 524, 598, 260, 679, 522, 382, 877, 524, 838, 919, 38, 285, 753, 259, 919, 830, 907, 692, 705, 301, 739, 482, 961, 398, 597, 919, 38, 285, 897, 588, 919, 42, 321, 259, 207, 884, 373, 663, 523, 464, 522, 447, 695, 778, 267, 400, 79, 961, 310, 269, 911, 494, 321, 430, 919, 289, 321, 391, 480, 387, 917, 746, 258, 101, 274, 411, 124]\n",
            "sample 4:\n",
            "[114, 260, 22, 940, 410, 944, 136, 38, 351, 755, 288, 785, 717, 522, 382, 571, 998, 340, 288, 898, 339, 132, 756, 321, 54, 349, 48, 244, 998, 406, 321, 581, 132, 33, 105, 321, 716, 541, 571, 48, 948, 284, 321, 54, 590, 265, 207, 108, 870, 756, 692, 54, 284, 48, 504, 522, 153, 900, 982, 321, 143, 207, 321, 251, 409, 919, 207, 155, 235, 963, 310, 156, 571, 808, 133, 669, 378, 330, 132, 836, 868, 210, 692, 666, 994, 383, 919]\n",
            "sample 5:\n",
            "[753, 135, 860, 210, 780, 919, 382, 605, 373, 860, 653, 857, 537, 692, 607, 488, 210, 888, 133, 276, 720, 480, 868, 930, 120, 321, 377, 154, 15, 538, 132, 615]\n",
            "\n",
            "\n",
            "length of all arrays = [30, 87, 87, 87, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbQ5w7VL4RZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking similarity:\n",
        "\n",
        "#1- naive code: [30, 104, 107, 160, 32]  (most similar to hashing trick(1st variant))\n",
        "#2- Keras code at any num_words: [26, 83, 76, 99, 31] (slightly different)\n",
        "# note: average of middle three entries(83,79, and 99) is equal to 87.\n",
        "\n",
        "#3- hashing trick (following are the variants):\n",
        "# max_length > a+0 or > a+100: [30, 104, 107, 160, 32]  (most similar to naive code)\n",
        "# max_length = a+0: [30, 104, 107, 159, 32]\n",
        "# max_length = a-20: [30, 104, 107, 139, 32]\n",
        "# max_length = a-60: [30, 99, 99, 99, 32]\n",
        "# max_length = a-70: [30, 89, 89, 89, 32]\n",
        "# max_length = a-72: [30, 87, 87, 87, 32]  (most similar to Keras code)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVHh7GFtO9Zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISLcLxmJOuBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remaining assignment will be completed by tomorrow, InshAllah"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}